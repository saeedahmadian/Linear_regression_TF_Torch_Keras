{
    "cells": [
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!git clone https://github.com/saeedahmadian/npy_desired_regular",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Cloning into 'npy_desired_regular'...\nremote: Enumerating objects: 6, done.\u001b[K\nremote: Counting objects: 100% (6/6), done.\u001b[K\nremote: Compressing objects: 100% (4/4), done.\u001b[K\nremote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (6/6), done.\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!ls npy_desired_regular",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "desired_data.npy  README.md\r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport mpl_toolkits.mplot3d as plt3d",
            "execution_count": 151,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.model_selection import train_test_split\ndata =np.load('npy_desired_regular/desired_data.npy')",
            "execution_count": 152,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "x = data[:,0:2].reshape((-1,2))\ny = data[:,2].reshape((-1,1))",
            "execution_count": 153,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size= 0.3)",
            "execution_count": 154,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "N_feature=2\nN_out=1",
            "execution_count": 155,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "with tf.name_scope('input'):\n    x_tf = tf.placeholder(shape=[None,N_feature],dtype= tf.float32, name='x_input')\n    y_tf = tf.placeholder(shape=[None,N_out],dtype= tf.float32,name='y_input')",
            "execution_count": 156,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "with tf.name_scope('weights'):\n#     w= tf.Variable(tf.truncated_normal([N_feature,N_out]),dtype= tf.float32, name='W')\n#     b= tf.Variable(tf.truncated_normal([N_out]),dtype= tf.float32, name='b')\n    w= tf.Variable(tf.zeros([N_feature,N_out]),dtype= tf.float32, name='W')\n    b= tf.Variable(tf.zeros([N_out]),dtype= tf.float32, name='b')",
            "execution_count": 198,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "with tf.name_scope('prediction'):\n    y_pred = tf.add(tf.matmul(x_tf,w),b)\n        ",
            "execution_count": 199,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "loss = tf.reduce_mean(tf.square(y_pred-y_tf))",
            "execution_count": 200,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "variable_list=[w,b]",
            "execution_count": 201,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "optimizer = tf.train.GradientDescentOptimizer(learning_rate=.1)",
            "execution_count": 202,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# 1-you can directly use minimize with respect to your variables"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "train_opt= optimizer.minimize(loss,var_list=variable_list)\n\"or\"",
            "execution_count": 168,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 168,
                    "data": {
                        "text/plain": "'or'"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# 2- You can see gradients and variables and do what you want to do"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "gradients, variables = zip(*optimizer.compute_gradients(loss))\ntrain_op = optimizer.apply_gradients(list(zip(gradients, variables)))\n",
            "execution_count": 184,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# 3- You can apply resterictions on your gradients based on whatever you need to do"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# \ngvs = optimizer.compute_gradients(loss,variable_list)\ncapped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\ntrain_op = optimizer.apply_gradients(capped_gvs)",
            "execution_count": 213,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "grad_w= tf.gradients(loss,w)",
            "execution_count": 143,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "grad_b = tf.gradients(loss,b)",
            "execution_count": 144,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import random\ndef sampling(data,batch_size):\n    return np.array(random.sample(list(data),batch_size))\n",
            "execution_count": 166,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "saver = tf.train.Saver()\ntf.summary.histogram(\"weights\",w)\ntf.summary.histogram(\"bias\",w)\ntf.summary.scalar(\"loss\",loss)\ntf.summary.scalar(\"grad_w\",grad_w)\ntf.summary.scalar(\"grad_b\",grad_b)\nall_summaries=tf.summary.merge_all()",
            "execution_count": 146,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "epochs= 3\nbatch_size=2\nwith tf.Session() as sess:\n#     summ_write=tf.summary.FileWriter('summary',sess.graph)\n    sess.run(tf.global_variables_initializer())\n    for epoch in range(epochs):\n        x_batch= sampling(x_train,batch_size)\n        y_batch = sampling(y_train,batch_size)\n#         print(x_batch.shape)\n#         print(x_batch)\n#         print(y_batch),dloss_dw,dloss_db, weights,bias\n        model, grads_vars,loss_value,y_predicted,weights,bias= sess.run([train_opt,capped_gvs,loss,y_pred,w,b],feed_dict={x_tf:x_batch,y_tf:y_batch})\n        print('epoch: {}, loss: {}'.format(epoch,loss_value))\n#         print(model_info)\n#         print('weights are :')\n#         print(weights)\n#         print('bias are : ')\n#         print(bias)\n#         print('grads with respect to w are:')\n#         print(dloss_dw)\n#         print('grads with respect to bias is:')\n#         print(dloss_db)",
            "execution_count": 216,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "epoch: 0, loss: 147996.5\nepoch: 1, loss: 340932.5\nepoch: 2, loss: 186605.0\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "grads_vars",
            "execution_count": 217,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 217,
                    "data": {
                        "text/plain": "[(array([[-1.],\n         [-1.]], dtype=float32), array([[0.],\n         [0.]], dtype=float32)),\n (array([-1.], dtype=float32), array([0.], dtype=float32))]"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "weights",
            "execution_count": 206,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 206,
                    "data": {
                        "text/plain": "array([[0.],\n       [0.]], dtype=float32)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bias",
            "execution_count": 207,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 207,
                    "data": {
                        "text/plain": "array([0.], dtype=float32)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "grads_vars[0][0].shape",
            "execution_count": 212,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 212,
                    "data": {
                        "text/plain": "(2, 1)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for grad,var in grads_vars:\n    print('gradient is :')\n    print(grad)\n    print('variavle is :')\n    print(var)\n    ",
            "execution_count": 208,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "gradient is :\n[[-1034886.]\n [ -817944.]]\nvariavle is :\n[[0.]\n [0.]]\ngradient is :\n[-1038.]\nvariavle is :\n[0.]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}